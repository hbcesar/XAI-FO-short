{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import data_params as input_data_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISEASE_PREFIX = input_data_params.disease\n",
    "assert DISEASE_PREFIX == 'dmd' or 'hd' or 'oi'\n",
    "\n",
    "DATASET_PREFIXES = ['prev', 'restr']\n",
    "\n",
    "embedding_method = 'e2v'\n",
    "\n",
    "seeded_emb = False\n",
    "\n",
    "if seeded_emb:\n",
    "    fixed_emb = '_seeded'\n",
    "    title_seeded = ' with fixed node embeddings'\n",
    "else:\n",
    "    fixed_emb = ''\n",
    "    title_seeded = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Result Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder for dataset 2 exists and will be loaded: c:\\Users\\rosa-\\Google Drive\\Msc_Bioinformatics\\thesis\\XAIFO-ThesisProject\\output\\hd\\g2_e2v\n",
      "A total of 10 runs will be included in the analysis.\n",
      "c:\\Users\\rosa-\\Google Drive\\Msc_Bioinformatics\\thesis\\XAIFO-ThesisProject\\output\\hd\\g2_e2v\\run_001\\pred\n",
      "c:\\Users\\rosa-\\Google Drive\\Msc_Bioinformatics\\thesis\\XAIFO-ThesisProject\\output\\hd\\g2_e2v\\run_002\\pred\n",
      "c:\\Users\\rosa-\\Google Drive\\Msc_Bioinformatics\\thesis\\XAIFO-ThesisProject\\output\\hd\\g2_e2v\\run_003\\pred\n",
      "c:\\Users\\rosa-\\Google Drive\\Msc_Bioinformatics\\thesis\\XAIFO-ThesisProject\\output\\hd\\g2_e2v\\run_004\\pred\n",
      "c:\\Users\\rosa-\\Google Drive\\Msc_Bioinformatics\\thesis\\XAIFO-ThesisProject\\output\\hd\\g2_e2v\\run_005\\pred\n",
      "c:\\Users\\rosa-\\Google Drive\\Msc_Bioinformatics\\thesis\\XAIFO-ThesisProject\\output\\hd\\g2_e2v\\run_006\\pred\n",
      "c:\\Users\\rosa-\\Google Drive\\Msc_Bioinformatics\\thesis\\XAIFO-ThesisProject\\output\\hd\\g2_e2v\\run_007\\pred\n",
      "c:\\Users\\rosa-\\Google Drive\\Msc_Bioinformatics\\thesis\\XAIFO-ThesisProject\\output\\hd\\g2_e2v\\run_008\\pred\n",
      "c:\\Users\\rosa-\\Google Drive\\Msc_Bioinformatics\\thesis\\XAIFO-ThesisProject\\output\\hd\\g2_e2v\\run_009\\pred\n",
      "c:\\Users\\rosa-\\Google Drive\\Msc_Bioinformatics\\thesis\\XAIFO-ThesisProject\\output\\hd\\g2_e2v\\run_010\\pred\n"
     ]
    }
   ],
   "source": [
    "curr_working_dir = os.getcwd()\n",
    "curr_output_dir = os.path.join(curr_working_dir, 'output', DISEASE_PREFIX)\n",
    "\n",
    "run_names_per_dataset = {}\n",
    "run_folders_per_dataset = {}\n",
    "pred_folders_per_dataset = {}\n",
    "\n",
    "for dataset_prefix in DATASET_PREFIXES:\n",
    "    dataset_output_dir = os.path.join(curr_output_dir, f'{dataset_prefix}_{embedding_method}{fixed_emb}')\n",
    "\n",
    "    if not os.path.exists(dataset_output_dir):\n",
    "        print('First, run the edge2vec embedding script. Then, run this script.')\n",
    "    else:\n",
    "        print(f'Output folder for dataset {dataset_prefix} exists and will be loaded: {dataset_output_dir}')\n",
    "        \n",
    "    run_folders_list = []\n",
    "    for item in os.listdir(dataset_output_dir):\n",
    "        curr_path = os.path.join(dataset_output_dir, item)\n",
    "        if os.path.isdir(curr_path) and 'run' in item:\n",
    "            run_folders_list.append(item)\n",
    "\n",
    "    run_names_per_dataset[dataset_prefix] = run_folders_list\n",
    "\n",
    "    print(f'For dataset {dataset_prefix}, a total of {len(run_folders_list)} runs will be included in the analysis.')\n",
    "\n",
    "    run_folders_paths = []\n",
    "    pred_folders_paths = []\n",
    "    for run_folder in run_folders_list:\n",
    "        run_path = os.path.join(dataset_output_dir, run_folder)\n",
    "        run_folders_paths.append(run_path)\n",
    "        pred_run_path = os.path.join(run_path, 'pred')\n",
    "        pred_folders_paths.append(pred_run_path)\n",
    "        print(pred_run_path)\n",
    "\n",
    "    run_folders_per_dataset[dataset_prefix] = run_folders_paths\n",
    "    pred_folders_per_dataset[dataset_prefix] = pred_folders_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_scores_all_runs_per_dataset = {}\n",
    "auc_loss_scores_all_runs_per_dataset = {}\n",
    "\n",
    "for dataset_prefix in DATASET_PREFIXES:\n",
    "    run_folders_list = run_names_per_dataset[dataset_prefix]\n",
    "    pred_folders_paths = pred_folders_per_dataset[dataset_prefix]\n",
    "\n",
    "    auc_scores_all_runs = []\n",
    "    auc_loss_scores_all_runs = []\n",
    "\n",
    "    for run_name, pred_folder in zip(run_folders_list, pred_folders_paths):\n",
    "        with open(f'{pred_folder}/{dataset_prefix}_{DISEASE_PREFIX}_performance_scores_{embedding_method}.pkl', 'rb') as f:\n",
    "            loaded_info = pickle.load(f)\n",
    "            \n",
    "        keys = ['AUC Train', 'AUC Validation', 'AUC Test']\n",
    "        for key in keys:\n",
    "            auc_scores = loaded_info[key]\n",
    "            for index, auc_score in enumerate(auc_scores):\n",
    "                auc_scores_per_run = {'run': run_name, 'name': key, 'iteration': index, 'score': auc_score}\n",
    "                auc_scores_all_runs.append(auc_scores_per_run)\n",
    "                auc_loss_scores_all_runs.append(auc_scores_per_run)\n",
    "\n",
    "        loss_scores = loaded_info['Loss']\n",
    "        for index, loss_score in enumerate(loss_scores):\n",
    "            formatted_loss_score = float(np.log10(loss_score))\n",
    "            loss_scores_per_run = {'run': run_name, 'name': 'Cross-Entropy Loss', 'iteration': index, 'score': formatted_loss_score}\n",
    "            auc_loss_scores_all_runs.append(loss_scores_per_run)\n",
    "\n",
    "    auc_scores_all_runs_per_dataset[dataset_prefix] = auc_scores_all_runs\n",
    "    auc_loss_scores_all_runs_per_dataset[dataset_prefix] = auc_loss_scores_all_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot ROC Curves, AUC-ROC Scores and F1 Scores for Each Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder for dataset 2 exists and will be loaded: c:\\Users\\rosa-\\Google Drive\\Msc_Bioinformatics\\thesis\\XAIFO-ThesisProject\\output\\hd\\g1_e2v\n",
      "A total of 10 runs will be included in the analysis.\n",
      "F1-Score in the test set of dataset 1 and method e2v: 0.9360192201071891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     26952\n",
      "           1       0.93      0.94      0.94     26952\n",
      "\n",
      "    accuracy                           0.94     53904\n",
      "   macro avg       0.94      0.94      0.94     53904\n",
      "weighted avg       0.94      0.94      0.94     53904\n",
      "\n",
      "F1-Score in the test set of dataset 1 and method e2v: 0.9390599078341014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     26952\n",
      "           1       0.93      0.95      0.94     26952\n",
      "\n",
      "    accuracy                           0.94     53904\n",
      "   macro avg       0.94      0.94      0.94     53904\n",
      "weighted avg       0.94      0.94      0.94     53904\n",
      "\n",
      "F1-Score in the test set of dataset 1 and method e2v: 0.9282963575225894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     26952\n",
      "           1       0.94      0.92      0.93     26952\n",
      "\n",
      "    accuracy                           0.93     53904\n",
      "   macro avg       0.93      0.93      0.93     53904\n",
      "weighted avg       0.93      0.93      0.93     53904\n",
      "\n",
      "F1-Score in the test set of dataset 1 and method e2v: 0.9361890041951865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     26952\n",
      "           1       0.93      0.94      0.94     26952\n",
      "\n",
      "    accuracy                           0.94     53904\n",
      "   macro avg       0.94      0.94      0.94     53904\n",
      "weighted avg       0.94      0.94      0.94     53904\n",
      "\n",
      "F1-Score in the test set of dataset 1 and method e2v: 0.9392401793457202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94     26952\n",
      "           1       0.93      0.94      0.94     26952\n",
      "\n",
      "    accuracy                           0.94     53904\n",
      "   macro avg       0.94      0.94      0.94     53904\n",
      "weighted avg       0.94      0.94      0.94     53904\n",
      "\n",
      "F1-Score in the test set of dataset 1 and method e2v: 0.9405796835082431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     26952\n",
      "           1       0.93      0.95      0.94     26952\n",
      "\n",
      "    accuracy                           0.94     53904\n",
      "   macro avg       0.94      0.94      0.94     53904\n",
      "weighted avg       0.94      0.94      0.94     53904\n",
      "\n",
      "F1-Score in the test set of dataset 1 and method e2v: 0.9326229326229326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     26952\n",
      "           1       0.93      0.94      0.93     26952\n",
      "\n",
      "    accuracy                           0.93     53904\n",
      "   macro avg       0.93      0.93      0.93     53904\n",
      "weighted avg       0.93      0.93      0.93     53904\n",
      "\n",
      "F1-Score in the test set of dataset 1 and method e2v: 0.6561808920362777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80     26952\n",
      "           1       0.99      0.49      0.66     26952\n",
      "\n",
      "    accuracy                           0.74     53904\n",
      "   macro avg       0.83      0.74      0.73     53904\n",
      "weighted avg       0.83      0.74      0.73     53904\n",
      "\n",
      "F1-Score in the test set of dataset 1 and method e2v: 0.9158485273492286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91     26952\n",
      "           1       0.91      0.92      0.92     26952\n",
      "\n",
      "    accuracy                           0.92     53904\n",
      "   macro avg       0.92      0.92      0.92     53904\n",
      "weighted avg       0.92      0.92      0.92     53904\n",
      "\n",
      "F1-Score in the test set of dataset 1 and method e2v: 0.9402364031373127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     26952\n",
      "           1       0.93      0.95      0.94     26952\n",
      "\n",
      "    accuracy                           0.94     53904\n",
      "   macro avg       0.94      0.94      0.94     53904\n",
      "weighted avg       0.94      0.94      0.94     53904\n",
      "\n",
      "Output folder for dataset 2 exists and will be loaded: c:\\Users\\rosa-\\Google Drive\\Msc_Bioinformatics\\thesis\\XAIFO-ThesisProject\\output\\hd\\g2_e2v\n",
      "A total of 10 runs will be included in the analysis.\n",
      "F1-Score in the test set of dataset 2 and method e2v: 0.832052209308193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87     40800\n",
      "           1       0.77      0.91      0.83     27200\n",
      "\n",
      "    accuracy                           0.85     68000\n",
      "   macro avg       0.85      0.86      0.85     68000\n",
      "weighted avg       0.87      0.85      0.85     68000\n",
      "\n",
      "F1-Score in the test set of dataset 2 and method e2v: 0.8408805136888695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.88     40800\n",
      "           1       0.77      0.92      0.84     27200\n",
      "\n",
      "    accuracy                           0.86     68000\n",
      "   macro avg       0.86      0.87      0.86     68000\n",
      "weighted avg       0.87      0.86      0.86     68000\n",
      "\n",
      "F1-Score in the test set of dataset 2 and method e2v: 0.7725198456368945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.64      0.77     40800\n",
      "           1       0.64      0.97      0.77     27200\n",
      "\n",
      "    accuracy                           0.77     68000\n",
      "   macro avg       0.81      0.80      0.77     68000\n",
      "weighted avg       0.84      0.77      0.77     68000\n",
      "\n",
      "F1-Score in the test set of dataset 2 and method e2v: 0.7442888725128961\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.58      0.72     40800\n",
      "           1       0.61      0.97      0.74     27200\n",
      "\n",
      "    accuracy                           0.73     68000\n",
      "   macro avg       0.78      0.77      0.73     68000\n",
      "weighted avg       0.82      0.73      0.73     68000\n",
      "\n",
      "F1-Score in the test set of dataset 2 and method e2v: 0.7443996064395613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.59      0.73     40800\n",
      "           1       0.61      0.96      0.74     27200\n",
      "\n",
      "    accuracy                           0.74     68000\n",
      "   macro avg       0.78      0.77      0.74     68000\n",
      "weighted avg       0.82      0.74      0.73     68000\n",
      "\n",
      "F1-Score in the test set of dataset 2 and method e2v: 0.743944537958974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.59      0.73     40800\n",
      "           1       0.61      0.96      0.74     27200\n",
      "\n",
      "    accuracy                           0.74     68000\n",
      "   macro avg       0.78      0.77      0.74     68000\n",
      "weighted avg       0.82      0.74      0.73     68000\n",
      "\n",
      "F1-Score in the test set of dataset 2 and method e2v: 0.7709337460387647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.64      0.77     40800\n",
      "           1       0.64      0.96      0.77     27200\n",
      "\n",
      "    accuracy                           0.77     68000\n",
      "   macro avg       0.80      0.80      0.77     68000\n",
      "weighted avg       0.83      0.77      0.77     68000\n",
      "\n",
      "F1-Score in the test set of dataset 2 and method e2v: 0.821401902535632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.78      0.85     40800\n",
      "           1       0.74      0.93      0.82     27200\n",
      "\n",
      "    accuracy                           0.84     68000\n",
      "   macro avg       0.84      0.85      0.84     68000\n",
      "weighted avg       0.86      0.84      0.84     68000\n",
      "\n",
      "F1-Score in the test set of dataset 2 and method e2v: 0.8448826454934124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89     40800\n",
      "           1       0.80      0.89      0.84     27200\n",
      "\n",
      "    accuracy                           0.87     68000\n",
      "   macro avg       0.86      0.87      0.87     68000\n",
      "weighted avg       0.87      0.87      0.87     68000\n",
      "\n",
      "F1-Score in the test set of dataset 2 and method e2v: 0.7046700574674681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.47      0.63     40800\n",
      "           1       0.55      0.98      0.70     27200\n",
      "\n",
      "    accuracy                           0.67     68000\n",
      "   macro avg       0.76      0.72      0.67     68000\n",
      "weighted avg       0.80      0.67      0.66     68000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "curr_working_dir = os.getcwd()\n",
    "curr_output_dir = os.path.join(curr_working_dir, 'output', DISEASE_PREFIX)\n",
    "\n",
    "final_test_auc_roc_scores_all_runs_all_models = []\n",
    "roc_curve_all_runs_all_models = []\n",
    "f1_scores_all_runs_all_models = []\n",
    "\n",
    "for dataset_prefix in DATASET_PREFIXES:\n",
    "    curr_dataset_output_dir = os.path.join(curr_output_dir, f'{dataset_prefix}_{embedding_method}{fixed_emb}')\n",
    "\n",
    "    if not os.path.exists(curr_dataset_output_dir):\n",
    "        print('First, run the edge2vec embedding script. Then, run this script.')\n",
    "    else:\n",
    "        print(f'Output folder for dataset {dataset_prefix} exists and will be loaded: {curr_dataset_output_dir}')\n",
    "            \n",
    "        run_folders_list = []\n",
    "        for item in os.listdir(curr_dataset_output_dir):\n",
    "            curr_path = os.path.join(curr_dataset_output_dir, item)\n",
    "            if os.path.isdir(curr_path) and 'run' in item:\n",
    "                run_folders_list.append(item)\n",
    "\n",
    "        print(f'A total of {len(run_folders_list)} runs will be included in the analysis.')\n",
    "\n",
    "        run_folders_paths = []\n",
    "        curr_pred_folders_paths = []\n",
    "        for run_folder in run_folders_list:\n",
    "            run_path = os.path.join(curr_dataset_output_dir, run_folder)\n",
    "            run_folders_paths.append(run_path)\n",
    "            pred_run_path = os.path.join(run_path, 'pred')\n",
    "            curr_pred_folders_paths.append(pred_run_path)\n",
    "            \n",
    "        for run_name, pred_folder in zip(run_folders_list, curr_pred_folders_paths):\n",
    "            with open(f'{pred_folder}/{dataset_prefix}_{DISEASE_PREFIX}_performance_scores_{embedding_method}.pkl', 'rb') as f:\n",
    "                loaded_info = pickle.load(f)\n",
    "\n",
    "            auc_roc_score = loaded_info['ROC AUC Score']\n",
    "            formatted_auc_roc_score = float(auc_roc_score)\n",
    "            auc_roc_score_per_run = {'Model': f'{dataset_prefix}_{embedding_method}{fixed_emb}', \n",
    "                                     'ROC AUC Score': formatted_auc_roc_score}\n",
    "            final_test_auc_roc_scores_all_runs_all_models.append(auc_roc_score_per_run)\n",
    "\n",
    "            roc_fpr_scores = loaded_info['ROC FPR']\n",
    "            roc_tpr_scores = loaded_info['ROC TPR']\n",
    "            \n",
    "            for fpr, tpr in zip(roc_fpr_scores, roc_tpr_scores):\n",
    "                auc_per_threshold_per_run = {'Model': f'{dataset_prefix}_{embedding_method}{fixed_emb}',\n",
    "                                             'ROC FPR': fpr, 'ROC TPR': tpr}\n",
    "                roc_curve_all_runs_all_models.append(auc_per_threshold_per_run)\n",
    "\n",
    "            f1_score = loaded_info['F1 Score']\n",
    "            formatted_f1_score = float(f1_score)\n",
    "            f1_score_per_run = {'Model': f'{dataset_prefix}_{embedding_method}{fixed_emb}', \n",
    "                                'F1 Score': formatted_f1_score}\n",
    "            f1_scores_all_runs_all_models.append(f1_score_per_run)\n",
    "\n",
    "            print(f'F1-Score in the test set of dataset {dataset_prefix} and method {embedding_method}:', f1_score)\n",
    "            print(classification_report(loaded_info['True Labels'], loaded_info['Predicted Labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROC FPR</th>\n",
       "      <th>ROC TPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.153458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.154126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.155091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.155684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124004</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.981765</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124005</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.981814</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124006</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.989412</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124007</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.989461</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124008</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124009 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model   ROC FPR   ROC TPR\n",
       "0       g1_e2v  0.000000  0.000000\n",
       "1       g1_e2v  0.000148  0.153458\n",
       "2       g1_e2v  0.000148  0.154126\n",
       "3       g1_e2v  0.000148  0.155091\n",
       "4       g1_e2v  0.000148  0.155684\n",
       "...        ...       ...       ...\n",
       "124004  g2_e2v  0.981765  1.000000\n",
       "124005  g2_e2v  0.981814  1.000000\n",
       "124006  g2_e2v  0.989412  1.000000\n",
       "124007  g2_e2v  0.989461  1.000000\n",
       "124008  g2_e2v  1.000000  1.000000\n",
       "\n",
       "[124009 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_curve_all_runs_all_models = pd.DataFrame(roc_curve_all_runs_all_models)\n",
    "roc_curve_all_runs_all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.set_title(f'ROC TPR/ROC FPR Distribution over Each Run for Each Model on {DISEASE_PREFIX.upper()}{title_seeded}')\n",
    "sns.scatterplot(data=roc_curve_all_runs_all_models, x=\"ROC FPR\", y=\"ROC TPR\", hue=\"Model\", s=1)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend(markerscale=10)\n",
    "\n",
    "fig.savefig(f'{curr_output_dir}/{DISEASE_PREFIX}_roc_curves.png', bbox_inches='tight')\n",
    "fig.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.936019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.939060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.928296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.936189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.939240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.940580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.932623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.656181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.915849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.940236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.832052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.840881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.772520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.744289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.744400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.743945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.770934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.821402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.844883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.704670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  F1 Score\n",
       "0   g1_e2v  0.936019\n",
       "1   g1_e2v  0.939060\n",
       "2   g1_e2v  0.928296\n",
       "3   g1_e2v  0.936189\n",
       "4   g1_e2v  0.939240\n",
       "5   g1_e2v  0.940580\n",
       "6   g1_e2v  0.932623\n",
       "7   g1_e2v  0.656181\n",
       "8   g1_e2v  0.915849\n",
       "9   g1_e2v  0.940236\n",
       "10  g2_e2v  0.832052\n",
       "11  g2_e2v  0.840881\n",
       "12  g2_e2v  0.772520\n",
       "13  g2_e2v  0.744289\n",
       "14  g2_e2v  0.744400\n",
       "15  g2_e2v  0.743945\n",
       "16  g2_e2v  0.770934\n",
       "17  g2_e2v  0.821402\n",
       "18  g2_e2v  0.844883\n",
       "19  g2_e2v  0.704670"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores_all_runs_all_models = pd.DataFrame(f1_scores_all_runs_all_models)\n",
    "f1_scores_all_runs_all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.set_title(f'F1 Scores Overview for Each Model on {DISEASE_PREFIX.upper()}{title_seeded}')\n",
    "sns.barplot(f1_scores_all_runs_all_models, x=\"Model\", y=\"F1 Score\", errorbar=\"sd\", color='cornflowerblue')\n",
    "ax.bar_label(ax.containers[0], fontsize=10, padding=5)\n",
    "ax.set_xlabel('Model Variant')\n",
    "ax.set_ylabel('F1 Score')\n",
    "\n",
    "fig.savefig(f'{curr_output_dir}/{DISEASE_PREFIX}_f1_scores.png', bbox_inches='tight')\n",
    "fig.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final AUC-ROC Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROC AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.974881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.975704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.973653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.975204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.973902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.976678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.974351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.971160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.962830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g1_e2v</td>\n",
       "      <td>0.974757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.950721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.955379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.954094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.947143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.946270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.944634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.951182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.952390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.951037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>g2_e2v</td>\n",
       "      <td>0.947325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  ROC AUC Score\n",
       "0   g1_e2v       0.974881\n",
       "1   g1_e2v       0.975704\n",
       "2   g1_e2v       0.973653\n",
       "3   g1_e2v       0.975204\n",
       "4   g1_e2v       0.973902\n",
       "5   g1_e2v       0.976678\n",
       "6   g1_e2v       0.974351\n",
       "7   g1_e2v       0.971160\n",
       "8   g1_e2v       0.962830\n",
       "9   g1_e2v       0.974757\n",
       "10  g2_e2v       0.950721\n",
       "11  g2_e2v       0.955379\n",
       "12  g2_e2v       0.954094\n",
       "13  g2_e2v       0.947143\n",
       "14  g2_e2v       0.946270\n",
       "15  g2_e2v       0.944634\n",
       "16  g2_e2v       0.951182\n",
       "17  g2_e2v       0.952390\n",
       "18  g2_e2v       0.951037\n",
       "19  g2_e2v       0.947325"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_auc_roc_scores_all_runs_all_models = pd.DataFrame(final_test_auc_roc_scores_all_runs_all_models)\n",
    "final_test_auc_roc_scores_all_runs_all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.set_title(f'AUC-ROC Scores Overview for Each Model on {DISEASE_PREFIX.upper()}{title_seeded}')\n",
    "sns.barplot(final_test_auc_roc_scores_all_runs_all_models, x=\"Model\", y=\"ROC AUC Score\", errorbar=\"sd\")\n",
    "ax.bar_label(ax.containers[0], fontsize=10, padding=10)\n",
    "ax.set_ylim(0.85,1) # 0.85, 1\n",
    "ax.set_xlabel('Model Variant')\n",
    "ax.set_ylabel('AUC-ROC Score')\n",
    "\n",
    "fig.savefig(f'{curr_output_dir}/{DISEASE_PREFIX}_auc_roc_scores.png', bbox_inches='tight')\n",
    "fig.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Training Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_prefix in DATASET_PREFIXES:\n",
    "    auc_scores_all_runs = auc_scores_all_runs_per_dataset[dataset_prefix]\n",
    "    auc_scores_all_runs = pd.DataFrame(auc_scores_all_runs)\n",
    "\n",
    "    auc_loss_scores_all_runs = auc_loss_scores_all_runs_per_dataset[dataset_prefix]\n",
    "    auc_loss_scores_all_runs = pd.DataFrame(auc_loss_scores_all_runs)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    ax.set_title(f'Training curve on dataset {dataset_prefix.upper()} {DISEASE_PREFIX.upper()}{title_seeded}')\n",
    "    sns.lineplot(data=auc_scores_all_runs, x='iteration', y='score', hue='name')\n",
    "    ax.set_ylim(0.8,1) # 0.85, 1\n",
    "    ax.set_xlabel('Iteration')\n",
    "    ax.set_ylabel('AUC-ROC Score')\n",
    "\n",
    "    fig.savefig(f'{dataset_output_dir}/{dataset_prefix}_{DISEASE_PREFIX}_training_curve.png', bbox_inches='tight')\n",
    "    fig.clear()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_title(f'Training curve on dataset {dataset_prefix.upper()} {DISEASE_PREFIX.upper()}{title_seeded}')\n",
    "    sns.lineplot(data=auc_loss_scores_all_runs, x='iteration', y='score', hue='name')\n",
    "    ax.set_ylim(top=1)\n",
    "    ax.set_xlabel('Iteration')\n",
    "    ax.set_ylabel('AUC-ROC/log10(Loss)')\n",
    "\n",
    "    fig.savefig(f'{dataset_output_dir}/{dataset_prefix}_{DISEASE_PREFIX}_training_curve_with_loss.png', bbox_inches='tight')\n",
    "    fig.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity between top scoring symptom-drug pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_similarity_matrix(similarity_matrix_df, mean_overlap_ratio, median_overlap_ratio, dataset_prefix):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_title(f'Overlap ratio (Mean: {round(mean_overlap_ratio, 2)}, Median: {round(median_overlap_ratio, 2)}) between list of predicted symptom-drug pairs per run on dataset {dataset_prefix.upper()} {DISEASE_PREFIX.upper()}{title_seeded}')\n",
    "    sns.heatmap(similarity_matrix_df, annot=True, fmt='.1f', linewidths=0.5, ax=ax, cmap='RdYlGn')\n",
    "    ax.collections[0].set_clim(0,100)\n",
    "\n",
    "    fig.savefig(f'{dataset_output_dir}/{dataset_prefix}_{DISEASE_PREFIX}_overlap_between_runs.png', bbox_inches='tight')\n",
    "    fig.clear()\n",
    "\n",
    "def get_pred_similarity_matrix(drug_symptom_pairs_per_run):\n",
    "    similarity_matrix = {}\n",
    "    ratios_non_diagonals = []\n",
    "    for index1, pairs1 in enumerate(drug_symptom_pairs_per_run):\n",
    "        similarities = {}\n",
    "        for index2, pairs2 in enumerate(drug_symptom_pairs_per_run):\n",
    "            overlap = set([tuple(sorted(ele)) for ele in pairs1]) & set([tuple(sorted(ele)) for ele in pairs2])\n",
    "            ratio_overlap = len(overlap) / total_drug_symptom_pairs * 100\n",
    "            \n",
    "            similarities[f'run {index2+1}'] = ratio_overlap\n",
    "            \n",
    "            if index1 != index2:\n",
    "                ratios_non_diagonals.append(ratio_overlap)\n",
    "            \n",
    "        similarity_matrix[f'run {index1+1}'] = similarities\n",
    "        \n",
    "    similarity_matrix_df = pd.DataFrame(similarity_matrix)\n",
    "    print('Similarity matrix:\\n', similarity_matrix_df)\n",
    "\n",
    "    mean_overlap_ratio = np.mean(ratios_non_diagonals)\n",
    "    median_overlap_ratio = np.median(ratios_non_diagonals)\n",
    "    print('Overlap ratio mean:', mean_overlap_ratio)\n",
    "    print('Overlap ratio median:', median_overlap_ratio)\n",
    "\n",
    "    visualize_similarity_matrix(similarity_matrix_df, mean_overlap_ratio, median_overlap_ratio, DATASET_PREFIX)\n",
    "\n",
    "def get_overlap_all_runs(drug_symptom_pairs_per_run, dataset_prefix):\n",
    "    for i in range(0, len(drug_symptom_pairs_per_run)):\n",
    "        if i == 0:\n",
    "            overlapping_pairs_all_runs = set(drug_symptom_pairs_per_run[i])\n",
    "        else:\n",
    "            overlapping_pairs_all_runs = overlapping_pairs_all_runs & set(drug_symptom_pairs_per_run[i])\n",
    "                \n",
    "    print(f'For dataset {dataset_prefix}, there are {len(overlapping_pairs_all_runs)} symptom-drug pairs that are found in the top list of drug candidates in {len(drug_symptom_pairs_per_run)} runs: \\n {overlapping_pairs_all_runs}')\n",
    "\n",
    "    with open(f'{dataset_output_dir}/symptom_drug_pair_overlapping_all_runs_{DISEASE_PREFIX}_{dataset_prefix}_{embedding_method}{fixed_emb}.pkl', 'wb') as f:\n",
    "        pickle.dump(overlapping_pairs_all_runs, f)\n",
    "\n",
    "def get_overlap_threshold_runs(drug_symptom_pairs_per_run, dataset_prefix, threshold):\n",
    "    same_drug_symptom_pairs_thresholded = set()\n",
    "\n",
    "    threshold = threshold\n",
    "    total_runs = len(drug_symptom_pairs_per_run)\n",
    "    min_nr_runs = int(threshold * total_runs)\n",
    "\n",
    "    for i in range(0, len(drug_symptom_pairs_per_run)):\n",
    "        for pair in drug_symptom_pairs_per_run[i]:\n",
    "            same_pairs = 0\n",
    "            for j in range(0, len(drug_symptom_pairs_per_run)):\n",
    "                for pair_to_compare in drug_symptom_pairs_per_run[j]:\n",
    "                    if pair == pair_to_compare:\n",
    "                        same_pairs += 1\n",
    "                            \n",
    "            if same_pairs >= min_nr_runs:\n",
    "                same_drug_symptom_pairs_thresholded.add(pair)\n",
    "                \n",
    "    print(f'There are {len(same_drug_symptom_pairs_thresholded)} symptom-drug pairs that are found in the top list of drug candidates in at least {min_nr_runs} of the {total_runs} runs: \\n {same_drug_symptom_pairs_thresholded}')\n",
    "\n",
    "    with open(f'{dataset_output_dir}/symptom_drug_pair_overlapping_{min_nr_runs}_runs_{DISEASE_PREFIX}_{dataset_prefix}_{embedding_method}{fixed_emb}.pkl', 'wb') as f:\n",
    "        pickle.dump(same_drug_symptom_pairs_thresholded, f)\n",
    "\n",
    "for dataset_prefix in DATASET_PREFIXES:\n",
    "    pred_folders_paths = pred_folders_per_dataset[dataset_prefix]\n",
    "    drug_symptom_pairs_per_run = []\n",
    "\n",
    "    for index, pred_path in enumerate(pred_folders_paths):\n",
    "        with open(f'{pred_path}/{dataset_prefix}_{DISEASE_PREFIX}_candidates_per_symptom_{embedding_method}.pkl', 'rb') as f:\n",
    "            loaded_list = pickle.load(f)\n",
    "            \n",
    "            drug_symptom_pairs = []\n",
    "            \n",
    "            for _, row in loaded_list.iterrows():\n",
    "                symptom_id = row['Symptom']\n",
    "                candidates = row['Candidates']\n",
    "                \n",
    "                for candidate in candidates:\n",
    "                    drug_symptom_pairs.append(tuple([symptom_id, candidate]))\n",
    "                    \n",
    "            total_drug_symptom_pairs = len(drug_symptom_pairs)\n",
    "        \n",
    "        drug_symptom_pairs_per_run.append(drug_symptom_pairs)\n",
    "\n",
    "    get_pred_similarity_matrix(drug_symptom_pairs_per_run)\n",
    "\n",
    "    get_overlap_all_runs(drug_symptom_pairs_per_run, dataset_prefix)\n",
    "    get_overlap_threshold_runs(drug_symptom_pairs_per_run, dataset_prefix, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check overlap between each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_working_dir = os.getcwd()\n",
    "curr_output_dir = os.path.join(curr_working_dir, 'output', DISEASE_PREFIX)\n",
    "\n",
    "overlapping_pairs = []\n",
    "\n",
    "for dataset_prefix in DATASET_PREFIXES:\n",
    "    nodes = pd.read_csv(f'{curr_output_dir}/{dataset_prefix}_{DISEASE_PREFIX}indexed_nodes.csv')\n",
    "    nodes.drop('index_id', axis=1, inplace=True)\n",
    "    nodes['semantic'] = nodes['semantic'].astype('category')\n",
    "\n",
    "    if dataset_prefix == 'prev':\n",
    "        drug_semantic = 'DRUG'\n",
    "    else:\n",
    "        drug_semantic = 'drug'\n",
    "\n",
    "    dataset_output_dir = os.path.join(curr_output_dir, f'{dataset_prefix}_{embedding_method}{fixed_emb}')\n",
    "    if not os.path.exists(dataset_output_dir):\n",
    "        print('First, run the edge2vec embedding script. Then, run this script.')\n",
    "    else:\n",
    "        print(f'Output folder for dataset {dataset_prefix} exists and will be loaded: {dataset_output_dir}')\n",
    "        \n",
    "        with open(f'{dataset_output_dir}/symptom_drug_pair_overlapping_all_runs_{DISEASE_PREFIX}_{dataset_prefix}_{embedding_method}{fixed_emb}.pkl', 'rb') as f:\n",
    "            loaded_list = pickle.load(f)\n",
    "            overlapping_pairs.append(loaded_list)\n",
    "            \n",
    "            pair_dict_list = []\n",
    "            for pair in loaded_list:\n",
    "                symptom_id, drug_id = pair\n",
    "                \n",
    "                symptom_name = nodes.loc[nodes['id'] == symptom_id]['label'].iloc[0]\n",
    "                \n",
    "                drug_name = nodes.loc[nodes['id'] == drug_id]['label'].iloc[0]\n",
    "                pair_dict_list.append({'Drug': drug_name, 'Symptom ID': symptom_id, 'Symptom': symptom_name})\n",
    "                \n",
    "            overlapping_all_runs_df = pd.DataFrame(pair_dict_list)\n",
    "\n",
    "            print(f'Drug-symptom pairs overlapping all runs:\\n', overlapping_all_runs_df)\n",
    "\n",
    "            overlapping_all_runs_df.to_csv(f'{dataset_output_dir}/symptom_drug_pair_overlapping_all_runs_{DISEASE_PREFIX}_{dataset_prefix}_{embedding_method}{fixed_emb}.csv', index=False)\n",
    "\n",
    "dataset1_emb_overlap = overlapping_pairs[0].intersection(overlapping_pairs[1])\n",
    "for pair in dataset1_emb_overlap:\n",
    "    symptom_id, drug_id = pair\n",
    "    symptom_name = nodes.loc[nodes['id'] == symptom_id]['label'].iloc[0]\n",
    "    drug_name = nodes.loc[nodes['id'] == drug_id]['label'].iloc[0]\n",
    "    print(drug_name, 'treats', symptom_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xaifognn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
